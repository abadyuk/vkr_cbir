{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline indexing_source.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf5z8CH7osLk"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import scipy.cluster.vq as vq\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "from tqdm.notebook import tqdm\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "8tvi2e4LoxMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "query_names = []\n",
        "query_imgs = []\n",
        "train_names = []\n",
        "train_imgs = []\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\"drive/My Drive/<your-folder>\"\n",
        "new_path = '/content/drive/MyDrive/UC_merced_data'\n",
        "i = 0\n",
        "\n",
        "for indir in os.listdir(\"drive/My Drive/UC_merced_data\"):\n",
        "    subdir = \"drive/My Drive/UC_merced_data/\" + indir                                                                                                                                          \n",
        "    imname = indir.strip()\n",
        "    imno = i\n",
        "    i += 1\n",
        "    img = cv2.imread(subdir, -1)\n",
        "  \n",
        "    if imno % 100 == 0:\n",
        "        if img.shape == (256, 256, 3):\n",
        "          query_names.append(imname)\n",
        "          query_imgs.append(img)\n",
        "    else:\n",
        "        if img.shape == (256, 256, 3):\n",
        "          train_names.append(imname)\n",
        "          train_imgs.append(img)"
      ],
      "metadata": {
        "id": "irGyxYMPo4OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ks3IsVZ_pT1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Индексация с помощью случайных K-d деревьев**\n"
      ],
      "metadata": {
        "id": "xEgc7ffmpKr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "\n",
        "class AlexNet(object):\n",
        "    def __init__(self):\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self._device = torch.device(device)\n",
        "\n",
        "        self.alexnet = torchvision.models.alexnet(pretrained=True)\n",
        "        self.alexnet.to(self._device)\n",
        "        self.alexnet.eval()\n",
        "\n",
        "    def embedding(self, cv_image):\n",
        "        image = torch.as_tensor(cv_image, dtype=torch.float32) / 255\n",
        "        image = image.permute(2, 1, 0).unsqueeze(0).to(self._device)\n",
        "        with torch.no_grad():\n",
        "            return self.alexnet(image).detach().squeeze().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "KM9S1z5MpBwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_desc = []\n",
        "train_desc = []\n",
        "A = AlexNet()\n",
        "\n",
        "for elem in query_imgs:\n",
        "    query_desc.append(A.embedding(elem))\n",
        "for elem in train_imgs:\n",
        "    print(elem.shape)\n",
        "    train_desc.append(A.embedding(elem))\n",
        "\n",
        "print(len(query_desc))\n",
        "print(len(train_desc))"
      ],
      "metadata": {
        "id": "tjFiFiIHpHsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_index_kdtrees(img_names, descriptors, n_trees):\n",
        "    \n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = n_trees)\n",
        "    search_params = {}  \n",
        "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "    \n",
        "    start = time.time()\n",
        "    flann.add(descriptors)\n",
        "    flann.train()\n",
        "    stop = time.time()\n",
        "\n",
        "    training_time = stop - start\n",
        "    \n",
        "    return flann, training_time \n"
      ],
      "metadata": {
        "id": "0exL6jCEpW2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_image(descs, flann_index, train_names, ratio):\n",
        "\n",
        "    ratio = 0.75\n",
        "    init_dict = [(img_name, 0) for img_name in train_names]\n",
        "    score = dict(init_dict)\n",
        "    start = time.time()\n",
        "    matches = flann_index.knnMatch(descs, k = 2) \n",
        "    stop = time.time()\n",
        "    filt_matches = list(filter(lambda m: m[0].distance < m[1].distance * ratio, matches))\n",
        "    for match in filt_matches: \n",
        "        score[train_names[match[0].imgIdx]]+=1\n",
        "\n",
        "\n",
        "    results = np.array(list(score.values()))\n",
        "    imgs_names = list(score.keys())\n",
        "    index_sort = np.argsort(results)[::-1]\n",
        "    best_imgs = [imgs_names[i] for i in index_sort]\n",
        "    \n",
        "    query_time = stop-start\n",
        "    return best_imgs, query_time\n"
      ],
      "metadata": {
        "id": "c7jyjqzmpuDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_dict = {} \n",
        "for indir in os.listdir(\"drive/My Drive/Images\"):\n",
        "    subdir = \"drive/My Drive/Images/\" + indir\n",
        "    names_list = []\n",
        "    for images in os.listdir(subdir): \n",
        "      names_list.append(images)\n",
        "    map_dict[indir] = names_list\n",
        "    \n",
        "\n",
        "\n",
        "def compute_recall(query_names, query_descs, index, train_names):\n",
        "   \n",
        "    total_results = {}\n",
        "    recall = 0.0\n",
        "    query_times = []\n",
        "    \n",
        "    for query_name, query_desc in zip(query_names, query_descs):\n",
        "        results, query_time = query_image(query_desc, index, train_names)\n",
        "        total_results[query_name] = results \n",
        "        query_times.append(query_time)\n",
        "\n",
        "    recall_array = []\n",
        "    for key, value in total_results.items():\n",
        "        intersection = [elem for elem in value if elem in res_dict[key[:-6]]]\n",
        "        recall_array.append(len(intersection)/len(res_dict[key[:-6]]))\n",
        "\n",
        "    return total_results, np.array(recall_array), np.array(query_times)\n"
      ],
      "metadata": {
        "id": "_Z9y7-TkruRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_train_time_kd = 0.0\n",
        "mean_query_time_kd = 0.0\n",
        "n_iters = 5\n",
        "\n",
        "for i in range(n_iters):\n",
        "    index, train_time_kd = build_index_kdtrees(train_names, train_desc, n_trees = 3)\n",
        "    results, recall, query_time_kd = compute_recall(query_names, query_desc, index, train_names)\n",
        "    mean_train_t_kd += train_time_kd\n",
        "    mean_query_t_kd += np.mean(query_time_kd)\n",
        "    print('Iteration {}\\n'.format(i))\n",
        "    print('Recall: {} \\n'.format(np.mean(recall)))\n",
        "    print('Training time: {} secs.'.format(train_time_kd))\n",
        "    print('Query response time: {} +- {} secs.'.format(np.mean(query_time_kd), np.std(query_time_kd)))\n",
        "    print('\\n\\n')"
      ],
      "metadata": {
        "id": "fS3Us0iMr-Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Индексация с помощью LSH-хешинга"
      ],
      "metadata": {
        "id": "tF5YU64AsWTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_kps_orb = []\n",
        "query_desc_orb = []\n",
        "train_kps_orb = []\n",
        "train_desc_orb = []\n",
        "\n",
        "\n",
        "orb = cv2.ORB_create(nfeatures = 1500, fastThreshold = 50)\n",
        "for query in query_imgs: \n",
        "    kp,des = orb.detectAndCompute(query, mask=None)\n",
        "    query_kps_orb.append(kp)\n",
        "    query_desc_orb.append(des)\n",
        "    \n",
        "for train in train_imgs: \n",
        "    kp,des = orb.detectAndCompute(train, mask=None)\n",
        "    train_kps_orb.append(kp)\n",
        "    train_desc_orb.append(des)\n",
        "    \n",
        "    \n",
        "print(len(query_kps_orb[0]))\n",
        "print(query_desc_orb[0].shape)\n",
        "print(query_desc_orb[0])\n"
      ],
      "metadata": {
        "id": "cfW3B9vysiNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_index_lsh(img_names, descriptors, tables, hash_size):\n",
        " \n",
        "    FLANN_INDEX_LSH = 6\n",
        "    index_params = dict(algorithm = FLANN_INDEX_LSH, table_number = tables, key_size = hash_size, multi_probe_level = 0)\n",
        "    search_params = {}  \n",
        "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "    \n",
        "    start = time.time()\n",
        "    flann.add(descriptors)\n",
        "    flann.train()\n",
        "    stop = time.time()\n",
        "    \n",
        "    training_time = stop - start\n",
        "\n",
        "    return flann, training_time\n"
      ],
      "metadata": {
        "id": "3u_80NufsrFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_train_time_lsh = 0.0\n",
        "mean_query_time_lsh = 0.0\n",
        "n_iters = 3\n",
        "\n",
        "for i in range(n_iters):\n",
        "    index, train_time_lsh = build_index_lsh(train_names, train_desc_orb, n_trees = 3)\n",
        "    results, recall, query_time_lsh = compute_recall(query_names, query_desc_orb, index, train_names)\n",
        "    mean_train_t_kd += train_time_lsh\n",
        "    mean_query_t_kd += np.mean(query_time_lsh)\n",
        "    print('Iteration {}\\n'.format(i))\n",
        "    print('Recall: {} \\n'.format(np.mean(recall)))\n",
        "    print('Training time: {} secs.'.format(train_time_lsh))\n",
        "    print('Query response time: {} +- {} secs.'.format(np.mean(query_time_lsh), np.std(query_time_lsh)))\n",
        "    print('\\n\\n')"
      ],
      "metadata": {
        "id": "5iCnrmbWtEVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BoVW(object):\n",
        "\n",
        "    def __init__(self, vocab_file):\n",
        "        self.vocab = vocab_file\n",
        "        self.nwords = self.vocab.getTrainDescriptors()[0].shape[0]\n",
        "      \n",
        "        init_dict = [(str(i), []) for i in range(self.nwords)] \n",
        "        self.inverted = dict(init_dict)\n",
        "       \n",
        "\n",
        "    def build_index(self, img_names, img_descs):\n",
        "       \n",
        "        start = time.time()\n",
        "        for name, descs in zip(img_names, img_descs): \n",
        "            matches = self.vocab.match(descs)\n",
        "            idxs = [match.trainIdx for match in matches]\n",
        "            unique_idxs = np.unique(np.array(idxs))\n",
        "            for idx in list(unique_idxs):\n",
        "                self.inverted[str(idx)].append(name)\n",
        "        stop = time.time()\n",
        "        training_time = stop-start\n",
        "        \n",
        "        return training_time\n",
        "    \n",
        "     \n",
        "\n",
        "    def query_image(self, descriptors):\n",
        "        \n",
        "        start = time.time()\n",
        "        matches = self.vocab.match(descriptors)\n",
        "        idxs = [match.trainIdx for match in matches]\n",
        "        counter = {}\n",
        "        for idx in idxs: \n",
        "            retrieved_imgs = self.inverted[str(idx)]\n",
        "            for ret_img in retrieved_imgs: \n",
        "                if ret_img not in list(counter.keys()):\n",
        "                    counter[ret_img] = 1\n",
        "                else: \n",
        "                    counter[ret_img] += 1\n",
        "        \n",
        "        values = np.array(list(counter.values()))\n",
        "        imgs_names = list(counter.keys())\n",
        "        index_sort = np.argsort(values)[::-1]\n",
        "        best_imgs = [imgs_names[i] for i in index_sort]\n",
        "        stop = time.time()\n",
        "        query_time = stop-start\n",
        "        \n",
        "        return best_imgs, query_time\n",
        "     "
      ],
      "metadata": {
        "id": "n7MPP7kctv8R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}